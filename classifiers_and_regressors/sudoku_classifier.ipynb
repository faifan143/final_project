{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "def generate_sudoku_player_stats():\n",
    "  \"\"\"Generates a random Sudoku player stats sample.\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the following keys:\n",
    "      * completion_time: The time it took the player to complete the Sudoku puzzle.\n",
    "      * hints: The number of hints the player used.\n",
    "      * mistakes: The number of mistakes the player made.\n",
    "      * is_completed: A boolean value indicating whether the player completed the Sudoku puzzle.\n",
    "      * level: The player's level.\n",
    "  \"\"\"\n",
    "\n",
    "  completion_time = random.randint(5, 30)\n",
    "  hints = random.randint(0, 3)\n",
    "  mistakes = random.randint(0, 3)\n",
    "  is_completed = random.randint(0, 1)\n",
    "  plevel = random.randint(1,4)\n",
    "  level = plevel\n",
    "\n",
    "  # Calculate the level.    \n",
    "  if completion_time < 10  and (mistakes == 0 and hints == 0) and is_completed == 1:\n",
    "    level = 4\n",
    "  elif completion_time < 10  and ( mistakes != 0 or hints!= 0 ) and is_completed== 1:\n",
    "    level = 3\n",
    "  elif completion_time < 10  and is_completed== 0:\n",
    "    level -= 1\n",
    "\n",
    "  elif (10<=completion_time) and  (completion_time < 20 ) and (mistakes ==0 and hints ==0) and is_completed== 1:\n",
    "    level = 3\n",
    "  elif (10<=completion_time) and  (completion_time < 20 ) and (mistakes !=0 or hints !=0) and is_completed == 1:\n",
    "    level = 2\n",
    "  elif (10<=completion_time) and  (completion_time < 20 ) and is_completed == 0:\n",
    "    level -= 1\n",
    "\n",
    "  elif  (20<=completion_time) and  (completion_time < 30 ) and (mistakes ==0 and hints == 0) and is_completed ==1:\n",
    "    level = 2\n",
    "  elif  (20<=completion_time) and  (completion_time < 30 ) and (mistakes !=0 or hints != 0) and is_completed ==1:\n",
    "    level = 1\n",
    "  elif  (20<=completion_time) and  (completion_time < 30 ) and is_completed == 0:\n",
    "    level -= 1\n",
    "\n",
    "  else :\n",
    "    level = 1\n",
    "\n",
    "  return {\n",
    "    \"completion_time\": completion_time,\n",
    "    \"hints\": hints,\n",
    "    \"mistakes\": mistakes,\n",
    "    \"is_completed\": is_completed,\n",
    "    \"previous_level\":plevel,\n",
    "    \"level\": 1 if level<=0 else level\n",
    "  }\n",
    "\n",
    "def generate_sudoku_players_stats_dataset(num_samples):\n",
    "  \"\"\"Generates a dataset of Sudoku players stats samples.\n",
    "\n",
    "  Args:\n",
    "    num_samples: The number of samples to generate.\n",
    "\n",
    "  Returns:\n",
    "    A list of dictionaries, where each dictionary contains the Sudoku player stats\n",
    "    for a single player.\n",
    "  \"\"\"\n",
    "\n",
    "  sudoku_players_stats_dataset = []\n",
    "  for i in range(num_samples):\n",
    "    sudoku_players_stats_dataset.append(generate_sudoku_player_stats())\n",
    "  return sudoku_players_stats_dataset\n",
    "\n",
    "# Generate a dataset of 100k Sudoku players stats samples.\n",
    "sudoku_players_stats_dataset = generate_sudoku_players_stats_dataset(1000000)\n",
    "\n",
    "df = pd.DataFrame(sudoku_players_stats_dataset)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"C:\\\\Users\\\\faisa\\\\Documents\\\\Games_Section\\\\chess\\\\CSVs\\\\sudoku_players_stats.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faisa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12500/12500 [==============================] - 28s 2ms/step - loss: 0.2708 - accuracy: 0.9446 - val_loss: 0.1352 - val_accuracy: 0.9736\n",
      "Epoch 2/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.1764 - accuracy: 0.9558 - val_loss: 0.1023 - val_accuracy: 0.9767\n",
      "Epoch 3/100\n",
      "12500/12500 [==============================] - 38s 3ms/step - loss: 0.1602 - accuracy: 0.9588 - val_loss: 0.0913 - val_accuracy: 0.9733\n",
      "Epoch 4/100\n",
      "12500/12500 [==============================] - 54s 4ms/step - loss: 0.1487 - accuracy: 0.9616 - val_loss: 0.0976 - val_accuracy: 0.9730\n",
      "Epoch 5/100\n",
      "12500/12500 [==============================] - 47s 4ms/step - loss: 0.1433 - accuracy: 0.9619 - val_loss: 0.0752 - val_accuracy: 0.9833\n",
      "Epoch 6/100\n",
      "12500/12500 [==============================] - 31s 3ms/step - loss: 0.1360 - accuracy: 0.9628 - val_loss: 0.0815 - val_accuracy: 0.9819\n",
      "Epoch 7/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.1301 - accuracy: 0.9638 - val_loss: 0.0653 - val_accuracy: 0.9848\n",
      "Epoch 8/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.1244 - accuracy: 0.9650 - val_loss: 0.0715 - val_accuracy: 0.9808\n",
      "Epoch 9/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.1154 - accuracy: 0.9670 - val_loss: 0.0691 - val_accuracy: 0.9725\n",
      "Epoch 10/100\n",
      "12500/12500 [==============================] - 47s 4ms/step - loss: 0.1060 - accuracy: 0.9699 - val_loss: 0.0512 - val_accuracy: 0.9884\n",
      "Epoch 11/100\n",
      "12500/12500 [==============================] - 36s 3ms/step - loss: 0.0978 - accuracy: 0.9729 - val_loss: 0.0497 - val_accuracy: 0.9890\n",
      "Epoch 12/100\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0904 - accuracy: 0.9748 - val_loss: 0.0426 - val_accuracy: 0.9904\n",
      "Epoch 13/100\n",
      "12500/12500 [==============================] - 32s 3ms/step - loss: 0.0804 - accuracy: 0.9777 - val_loss: 0.0470 - val_accuracy: 0.9919\n",
      "Epoch 14/100\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0778 - accuracy: 0.9781 - val_loss: 0.0414 - val_accuracy: 0.9889\n",
      "Epoch 15/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.0712 - accuracy: 0.9803 - val_loss: 0.0388 - val_accuracy: 0.9893\n",
      "Epoch 16/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.0652 - accuracy: 0.9817 - val_loss: 0.0535 - val_accuracy: 0.9787\n",
      "Epoch 17/100\n",
      "12500/12500 [==============================] - 28s 2ms/step - loss: 0.0606 - accuracy: 0.9831 - val_loss: 0.0298 - val_accuracy: 0.9940\n",
      "Epoch 18/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0585 - accuracy: 0.9836 - val_loss: 0.0278 - val_accuracy: 0.9935\n",
      "Epoch 19/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0556 - accuracy: 0.9841 - val_loss: 0.0513 - val_accuracy: 0.9770\n",
      "Epoch 20/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0532 - accuracy: 0.9846 - val_loss: 0.0255 - val_accuracy: 0.9926\n",
      "Epoch 21/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0510 - accuracy: 0.9855 - val_loss: 0.0294 - val_accuracy: 0.9937\n",
      "Epoch 22/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0485 - accuracy: 0.9861 - val_loss: 0.0238 - val_accuracy: 0.9966\n",
      "Epoch 23/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.0464 - accuracy: 0.9865 - val_loss: 0.0226 - val_accuracy: 0.9935\n",
      "Epoch 24/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.0328 - val_accuracy: 0.9915\n",
      "Epoch 25/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0206 - val_accuracy: 0.9955\n",
      "Epoch 26/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0208 - val_accuracy: 0.9935\n",
      "Epoch 27/100\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.0204 - val_accuracy: 0.9986\n",
      "Epoch 28/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0225 - val_accuracy: 0.9890\n",
      "Epoch 29/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0215 - val_accuracy: 0.9989\n",
      "Epoch 30/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 0.0242 - val_accuracy: 0.9889\n",
      "Epoch 31/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 0.0188 - val_accuracy: 0.9947\n",
      "Epoch 32/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0382 - accuracy: 0.9885 - val_loss: 0.0183 - val_accuracy: 0.9963\n",
      "Epoch 33/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0381 - accuracy: 0.9883 - val_loss: 0.0204 - val_accuracy: 0.9941\n",
      "Epoch 34/100\n",
      "12500/12500 [==============================] - 28s 2ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 0.0183 - val_accuracy: 0.9989\n",
      "Epoch 35/100\n",
      "12500/12500 [==============================] - 28s 2ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0188 - val_accuracy: 0.9912\n",
      "Epoch 36/100\n",
      "12500/12500 [==============================] - 29s 2ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
      "Epoch 37/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0183 - val_accuracy: 0.9989\n",
      "Epoch 38/100\n",
      "12500/12500 [==============================] - 29s 2ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.0177 - val_accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "12500/12500 [==============================] - 26s 2ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0177 - val_accuracy: 0.9989\n",
      "Epoch 40/100\n",
      "12500/12500 [==============================] - 24s 2ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0176 - val_accuracy: 0.9989\n",
      "Epoch 41/100\n",
      "12500/12500 [==============================] - 25s 2ms/step - loss: 0.0362 - accuracy: 0.9890 - val_loss: 0.0168 - val_accuracy: 0.9989\n",
      "Epoch 42/100\n",
      "12500/12500 [==============================] - 28s 2ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0175 - val_accuracy: 0.9989\n",
      "Epoch 43/100\n",
      "12500/12500 [==============================] - 31s 2ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0171 - val_accuracy: 0.9989\n",
      "Epoch 44/100\n",
      "12500/12500 [==============================] - 31s 2ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0177 - val_accuracy: 0.9989\n",
      "Epoch 45/100\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0170 - val_accuracy: 0.9989\n",
      "Epoch 46/100\n",
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0353 - accuracy: 0.9892 - val_loss: 0.0174 - val_accuracy: 0.9989\n",
      "3125/3125 [==============================] - 3s 957us/step - loss: 0.0168 - accuracy: 0.9987\n",
      "Test Accuracy: 0.9987300038337708\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\faisa\\\\Documents\\\\Games_Section\\\\chess\\\\CSVs\\\\sudoku_players_stats.csv\")\n",
    "\n",
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = data[[\"completion_time\",\"hints\",\"mistakes\",\"is_completed\",\"previous_level\"]]\n",
    "y = data[\"level\"]\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "np.save(\"sudoku_encoded_labels.npy\", label_encoder.classes_)\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(5,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Implement learning rate scheduling\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=10000, decay_rate=0.9, staircase=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train_encoded,\n",
    "    epochs=100,  # Increase the number of epochs\n",
    "    batch_size=64,  # Adjust batch size\n",
    "    validation_data=(X_val, y_val_encoded),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1  # Use verbose mode 2 for more detailed training output\n",
    ")\n",
    "\n",
    "\n",
    "# Save the model to a file\n",
    "model.save_weights(\"sudoku_weights.keras\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "weights_path = {\n",
    "    \"sudoku\":\"sudoku_weights.keras\",\n",
    "    \"missing_words\":\"missing_words_weights.keras\",\n",
    "    \"puzzle\":\"puzzle_weights.keras\" }\n",
    "classes_path = {\n",
    "    \"sudoku\":\"sudoku_encoded_labels.npy\",\n",
    "    \"missing_words\":\"missing_words_encoded_labels.npy\",\n",
    "    \"puzzle\":\"puzzle_encoded_labels.npy\" }\n",
    "\n",
    "\n",
    "def predict(features,game):\n",
    "    \"\"\"\n",
    "    features[0] = completion_time \n",
    "    features[1] = hints \n",
    "    features[2] = mistakes \n",
    "    features[3] = is_completed \n",
    "    features[4] = previous_level \n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(5,)),\n",
    "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(4,activation='softmax')\n",
    "    ])\n",
    "    model.load_weights(weights_path[game])\n",
    "    features = np.array([features])\n",
    "    predicted_probs = model.predict(features)\n",
    "    predicted_class = np.argmax(predicted_probs)\n",
    "    class_labels = np.load(classes_path[game])\n",
    "    predicted_level = class_labels[predicted_class]\n",
    "    return predicted_level\n",
    "\n",
    "\n",
    "print(predict([5,0,1,1,3],'sudoku'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faisa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.1.5:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:32:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:33:10] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:33:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:34:49] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002098D338A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:36:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002098D338040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:36:35] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:36:52] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:40:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:41:37] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 22:41:47] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:03:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:03:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:05:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:09:38] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:10:57] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:48:00] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:48:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:48:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:49:24] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:50:10] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.1.6 - - [10/Nov/2023 23:53:55] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "weights_path = {\n",
    "    \"sudoku\": \"sudoku_weights.keras\",\n",
    "    \"missing_words\": \"missing_words_weights.keras\",\n",
    "    \"puzzle\": \"puzzle_weights.keras\"\n",
    "}\n",
    "classes_path = {\n",
    "    \"sudoku\": \"sudoku_encoded_labels.npy\",\n",
    "    \"missing_words\": \"missing_words_encoded_labels.npy\",\n",
    "    \"puzzle\": \"puzzle_encoded_labels.npy\"\n",
    "}\n",
    "\n",
    "\n",
    "def predict(features, game):\n",
    "    \"\"\"\n",
    "    features[0] = completion_time\n",
    "    features[1] = hints\n",
    "    features[2] = mistakes\n",
    "    features[3] = is_completed\n",
    "    features[4] = previous_level\n",
    "    \"\"\"\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(5,)),\n",
    "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.load_weights(weights_path[game])\n",
    "    features = np.array([features])\n",
    "    predicted_probs = model.predict(features)\n",
    "    predicted_class = np.argmax(predicted_probs)\n",
    "    class_labels = np.load(classes_path[game])\n",
    "    predicted_level = class_labels[predicted_class]\n",
    "    return predicted_level\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict_level():\n",
    "    \"\"\"\n",
    "    Endpoint to predict the next level for a given set of features.\n",
    "\n",
    "    Request body:\n",
    "        {\n",
    "            \"features\": [\n",
    "                    completion_time, \n",
    "                    hints,\n",
    "                    mistakes,\n",
    "                    is_completed,\n",
    "                    previous_level\n",
    "                  ],\n",
    "\n",
    "\n",
    "                  \n",
    "            \"game\": \"sudoku\" | \"missing_words\" | \"puzzle\" , \"connect4\" , \"chess\" , \"dots_boxes\" , \"memory_card\" ,  \n",
    "        }\n",
    "\n",
    "    Response body:\n",
    "        {\n",
    "            \"predicted_level\": <predicted_level>\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    features = request.get_json()[\"features\"]\n",
    "    game = request.get_json()[\"game\"]\n",
    "\n",
    "    predicted_level = predict(features, game)\n",
    "    \n",
    "    predicted_level_string = str(predicted_level)\n",
    "    \n",
    "    return jsonify({\"predicted_level\": predicted_level_string})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
